\documentclass[10pt, a4paper, hidelinks]{article}
\usepackage[paper=a4paper, left=2cm, right=2cm, bottom=2cm, top=3cm]{geometry} %ajustar márgnens
\usepackage[latin1]{inputenc}
\usepackage[spanish]{babel}
\usepackage{caratula}
\usepackage{enumitem} 
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage[font=small,labelfont=bf]{caption}
\newcommand\floor[1]{\lfloor#1\rfloor}
\newcommand\ceil[1]{\lceil#1\rceil}
%\usepackage{clrscode3e} Estilo Cormen
\usepackage[spanish,onelanguage,ruled,vlined,nofillcomment]{algorithm2e}
\usepackage{algpseudocode}
\usepackage{xcolor}
\usepackage[final]{pdfpages} % para agregar el enunciado
%%%%%%%%%%%%%% Formato de párrafos %%%%%%%%%%%%%%%%%%
\setlength{\parindent}{2em}
\setlength{\parskip}{3pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{fancyhdr}
\usepackage{lastpage}
\setlength{\intextsep}{0.2cm}
\pagestyle{fancy}
\lhead{Sistemas Operativos}
\rhead{$1^{\mathrm{er}}$ cuatrimestre de 2018}

\LinesNumbered
\DontPrintSemicolon

\newcommand{\comp}[1]{$\mathcal{O}(#1)$}

%%%%%%%%%%%%%%%%%%% Macro para comentar codigo %%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\comentario}[1]{
\SetKwComment{Comment}{/* }{ */}
\textcolor{blue}{\Comment*[h]{{#1}}}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\materia{Sistemas Operativos}
\submateria{Primer cuatrimestre del 2018}
\titulo{Trabajo Práctico 1: \texttt{pthreads}}
\integrante{Budiño, Gabriel Fabricio}{046/16}{gabriel.f.budi@gmail.com} % obligatorio 
\integrante{Garro, Damián Eugenio}{354/16}{damian.garro.mst@gmail.com} % obligatorio 
\integrante{Rozenberg, Uriel Jonathan    \includegraphics[height=0.4cm]{img/barba.png}}{838/12}{rozenberguriel@gmail.com} % obligatorio 

\maketitle

\tableofcontents
\pagenumbering{gobble}

\pagebreak
\pagenumbering{arabic}
\cfoot{\thepage /\pageref{LastPage}}

\section{Introducción}
Para este trabajo se debía implementar la clase ConcurrentHashMap, una tabla de $hash$ abierta con interfaz de Map (i.e, diccionario) preparada para ser usada por $threads$ concurrentes. 

Se presenta en este informe un breve resumen de la resolución de cada ejercicio y la experimentación y pruebas realizadas. En el Apéndice A se encuentra el enunciado del trabajo, y en el Apéndice B se encuentran aclaraciones sobre decisiones tomadas a causa de no poder compilar los tests y al mismo tiempo cumplir con lo que pide el enunciado. 


\section{Resolución}
\subsection{Ejercicio 1}

El primer paso era completar la clase \texttt{Lista} entregada por la cátedra implementando \texttt{push\_front} de manera que sea \textit{atómica} y no haya peligro de $race$ $conditions$. 

Para esta operación se crea un nuevo nodo con el valor pasado a como parámetro, \texttt{nuevo}, y se hace que apunte como siguiente al actual primer nodo, \texttt{head}. Acá faltaría solo asignar \texttt{nuevo} a \texttt{head} de modo que éste sea el actual primer nodo, pero podría pasar que entre la asignación de \texttt{nuevo$\rightarrow$next} y este último paso alguien más haga un \texttt{push\_front}, no cumpliendo así la condición de que no haya peligro de $race$ $conditions$. Para resolver esto, se realiza esa asignación de la siguiente manera:

\texttt{while (not atomic\_compare\_exchange\_weak(\&head, \&nuevo$\rightarrow$next,nuevo))}

La función dentro de la guarda se comporta así, de forma atómica:
\begin{itemize}
\item Si \texttt{head} es igual a \texttt{nuevo$\rightarrow$next} (i.e, si el \texttt{head} no cambió desde que hicimos que \texttt{nuevo} lo apunte), devuelve True y asigna a \texttt{head}, \texttt{nuevo}.
\item Si se da el caso contrario (i.e, el \texttt{head} cambio desde que hicimos que \texttt{nuevo} lo apunte), devuelve False y asigna a \texttt{nuevo$\rightarrow$next}, \texttt{head}, es decir, hace que \texttt{nuevo} apunte al \texttt{head} correcto.
\end{itemize}

Como la misma se encuentra negada dentro de un while, solo se vuelve del llamado de \texttt{push\_front} cuando no hay peligro de incoherencias a causa del orden de ejecución.

Luego había que implementar la clase \texttt{ConcurrentHashMap}, cuya representación interna es un vector de listas de pares de 26 entradas, \texttt{tabla} (una por cada letra) y un vector de mutex, \texttt{mutexes} de igual cantidad de entradas. 

Para el constructor, \texttt{ConcurrentHashMap()}, simplemente se crea en cada entrada de \texttt{tabla} una nueva lista de pares vacía.

Para la función \texttt{void addAndInc(string key)} se debía garantizar contensión solo en caso de colisión de $hash$. Para lograr esto, se hace $locking$ en la entrada de \texttt{tabla} que se va a modificar usando el arreglo \texttt{mutexes}, de manera que ejecuciones concurrentes se permitan siempre que se trate de escrituras a distintas listas.  


\begin{algorithm}[H]

\SetKwProg{Fn}{Función}{}{fin}

\SetAlgoLined
\Fn{addAndInc(key)}{
	\texttt{i} $\leftarrow$ función de hash de \texttt{key} \\
	\texttt{mutexes[i].lock} \\
	iterar \texttt{tabla[i]} buscando \texttt{key} \\
	\If{está} {sumar 1 a su valor}
    \Else{\texttt{tabla[i].push\_front(key)}}
    \texttt{mutexes[i].unlock} \\
}
\caption{addAndInc}
\end{algorithm} 

Para la función \texttt{bool member(string key)}, simplemente se obtiene \texttt{i} de la misma forma que antes y se recorre la entrada correspondiente de \texttt{tabla} con un iterador, si el elemento está se devuelve True y en caso contrario se devuelve False. Esta operación es \textit{wait free} ya que no se aplica ningún mecanismo de $locking$. Podría ocurrir que en el medio de la operación se ejecute un \texttt{push\_front} del elemento buscado, y que \texttt{member} devolviese False o True dependiendo de si ya había empezado a recorrer la entrada de la tabla o no. Esto no es un problema, porque ambos resultados se corresponden con una posible ejecución secuencial de las operaciones.

Para la función \texttt{pair<string, unsigned int>maximum(unsigned int nt)} se definieron una una estructura y una función auxiliar, así que primero explicamos eso.

Se definió antes una estructura \texttt{Busqueda}, compuesta por un un puntero \texttt{ConcurrentHashMap} \texttt{mapa}, un entero atómico \texttt{contador}, un par \texttt{max} y un mutex \texttt{mtx\_max}. 

También se definió la función \texttt{void* buscador(void* data)}, cuyo pseudocódigo es el siguiente.

\begin{algorithm}[H]
\SetKwProg{Fn}{Función}{}{fin}

\SetAlgoLined
\Fn{buscador(data)}{
	\texttt{busqueda} $\leftarrow$ \texttt{data} como puntero a \texttt{Busqueda} \\
	\texttt{max} $\leftarrow$ \texttt{($``"$, 0)} \\
	\While{\texttt{true}} {
		\texttt{i} $\leftarrow$ \texttt{busqueda.contador++} \\
		\If{\texttt{i} $> 25$} {terminar}	
		iterar \texttt{busqueda.mapa[i]}\\
		\If{algún elemento tiene valor mayor al valor de \texttt{max}}{
		actualizar \texttt{max} con ese elemento		
		}
	}
	\texttt{busqueda.mtx\_max.lock} \\
	\If{el valor de \texttt{max} es mayor que el del \texttt{busqueda.max}}{
		\texttt{busqueda.max} $\leftarrow$ \texttt{max} \\
	}
	\texttt{busqueda.mtx\_max.unlock} \\
}
\caption{buscador}
\end{algorithm} 

Originalmente la guarda del \texttt{while} era \texttt{i} $< 26$, pero vimos que un scheduling particular podría traer errores luego haciendo que un $thread$ intente iterar una entrada mayor a 25, por lo que se cambio la guarda a \texttt{true} y luego de la asignación de \texttt{i}, si resulta este ser mayor o igual a 26 se hace un \texttt{break}. La única sección crítica acá es la actualización del máximo, que se resolvió usando $locking$ con el mutex interno de la estructura \texttt{Busqueda}.

Ahora, haciendo uso de la estructura y la función mencionadas, el pseudocódigo de \texttt{maximum} es el siguiente.

\begin{algorithm}[H]
\SetKwProg{Fn}{Función}{}{fin}

\SetAlgoLined
\Fn{maximum(nt)}{
	lock a todas las entradas de \texttt{mutexes} \\
	\texttt{busqueda} $\leftarrow$ nueva \texttt{Busqueda} \\
	\texttt{busqueda.mapa} $\leftarrow$ \texttt{this} \\
	\texttt{busqueda.contador} $\leftarrow$ \texttt{0} \\
	\texttt{busqueda.max} $\leftarrow$ \texttt{($``"$, 0)} \\
	crear \texttt{nt} threads y pasarles \texttt{busqueda} y la función \texttt{buscador} como punto de inicio \\
	esperar que terminen los \texttt{nt} threads \\
	unlock a todas las entradas de \texttt{mutexes} \\
	devolver \texttt{busqueda.max}
}
\caption{maximum}
\end{algorithm} 

Este ejercicio pedía concurrencia interna, la cual se logra usando el entero atómico \texttt{contador}, esto me asegura que durante la ejecución de \texttt{maximum} cada $thread$ va a trabajar sobre una entrada diferente. Aún así, para asegurarnos de que no sea concurrente con \texttt{addAndInc} se debe hacer lock a todos las entradas de \texttt{mutexes} y unlock solo al terminar. 

\subsection{Ejercicio 2}

En este punto no debíamos preocuparnos por la concurrencia. Así que la función  \texttt{count\_words(string arch)} es simplemente abrir el arhivo \texttt{arch} e ir pasando los strings capturados a un \texttt{ConcurrentHashMap} haciendo uso de \texttt{addAndInc}.

En lugar de hacer esto directamente, implementamos una función \texttt{meterEnMapa(ConcurrentHashMap* mapa, string arch)} que toma un puntero a \texttt{ConcurrentHashMap} y un archivo y hace lo descripto anteriormente. Esto es porque es algo que vamos a usar mucho. Luego, \texttt{count\_words(string arch)} solo crea un \texttt{ConcurrentHashMap} \texttt{mapa} y lo llena usando \texttt{meterEnMapa} antes de devolverlo.

\subsection{Ejercicio 3}

Para este ejercicio se volvieron a definir una estructura y una función para ayudarnos. La estructura \texttt{Wrapper\_count\_words1} consta de un puntero a \texttt{ConcurrentHashMap mapa} y un \texttt{string arch}. La función \texttt{void* thread\_count\_words1(void* data)} castea \texttt{data} a un puntero a \texttt{Wrapper\_count\_words1} \texttt{wrap} y luego llama a \texttt{meterEnMapa} con \texttt{wrap$\rightarrow$mapa} y \texttt{wrap$\rightarrow$arch} como parámetros.

Usando la función y la estructura recien definidas, el pseudocódigo de \texttt{count\_words} es el siguiente.

\begin{algorithm}[H]
\SetKwProg{Fn}{Función}{}{fin}

\SetAlgoLined
\Fn{count\_words(archs)}{
	\texttt{nt} $\leftarrow$ largo de \texttt{archs} \\
	\texttt{mapa} $\leftarrow$ nuevo \texttt{ConcurrentHashMap} \\
	\texttt{wrap} $\leftarrow$ arreglo de \texttt{nt} \texttt{Wrapper\_count\_words1} \\
	\ForEach{entrada de \texttt{wrap}}{
		asignarle un archivo disntinto de \texttt{archs} y la dirección de \texttt{mapa}	
	}
	crear \texttt{nt} threads y pasarle una entrada de \texttt{wrap} y \texttt{thread\_count\_words1} como punto de inicio \\
	esperar que terminen los \texttt{nt} threads \\
	devolver \texttt{mapa}
}
\caption{count\_words del Ejercicio 3}
\end{algorithm} 

Cada $thread$ tiene en su \texttt{wrap} un archivo distinto, pero todos tienen el mismo \texttt{mapa}, por lo que al final éste contiene los datos de todos los archivos.

\subsection{Ejercicio 4}

Se definió la estructura \texttt{Wrapper\_count\_words2}, que consta de un puntero a \texttt{ConcurrentHashMap mapa}, un puntero a mutex \texttt{mutexLista} y dos iteradores de lista de string, \texttt{it} y \texttt{ends}.

La función \texttt{thread\_count\_words2} tiene el siguiente pseudocodigo:

\begin{algorithm}[H]
\SetKwProg{Fn}{Función}{}{fin}

\SetAlgoLined
\Fn{thread\_count\_words2($data$)}{
	\texttt{wrap} $\leftarrow$ \texttt{data} como puntero a \texttt{Wrapper\_count\_words2} \\
	\texttt{arch} $\leftarrow$ nuevo string \\
	\While{true}{
		\texttt{wrap.mutexLista.lock} \\
		\If{\texttt{wrap.it} == \texttt{wrap.ends}}{
			\texttt{wrap.mutexLista.unlock} \\
			terminar	
		}
		\texttt{arch} $\leftarrow$ \texttt{wrap.it} \\
		\texttt{wrap.it++} \\
		\texttt{wrap.mutexLista.unlock} \\
		\texttt{meterEnMapa(wrap.mapa, arch)} \\
	}
}
\caption{thread\_count\_words2}
\end{algorithm}

Esta será la función con la que iniciemos los $threads$ de este punto. Usamos los iteradores \texttt{it} y \texttt{ends} para saber cuando se han tomado todos los archivos de la lista, siendo \texttt{it} el que apunta al siguiente archivo aún no tomado y \texttt{ends} el final de la lista. La modificación de estos iteradores está contenida con $locking$ usando el mutex de \texttt{Wrapper\_count\_words2}.

Así, el pseudocódigo de \texttt{count\_words(unsigned int n, list<string>archs)} es el siguiente:

\begin{algorithm}[H]
\SetKwProg{Fn}{Función}{}{fin}

\SetAlgoLined
\Fn{count\_words($n$, $archs$)}{
	\texttt{mapa} $\leftarrow$ nuevo \texttt{ConcurrentHashMap} \\
	\texttt{wrap} $\leftarrow$ nuevo \texttt{Wrapper\_count\_words2} \\
	\texttt{wrap.mapa} $\leftarrow$ dirección de \texttt{mapa} \\
	\texttt{wrap.mutexLista} $\leftarrow$ nuevo mutex \\
	\texttt{wrap.it} $\leftarrow$ \texttt{archs.begin} \\
	\texttt{wrap.ends} $\leftarrow$ \texttt{archs.end} \\
	crear \texttt{n} threads con el puntero a \texttt{wrap} y la función \texttt{thread\_count\_words2} como punto de inicio \\
	esperar que que terminen los \texttt{n} threads \\
	devolver \texttt{mapa}
}
\caption{count\_words del Ejercicio 4}
\end{algorithm}

Notar que los \texttt{n} threads comparten el mismo \texttt{ConcurrentHashMap}. Cada uno se encargará de archivos diferentes (gracias a \texttt{mutexLista}) hasta que no queden más sin cargar en la lista como se vió en la función definida antes, y la contensión está cubierta por \texttt{addAndInc}.

\subsection{Ejercicio 5}

La estructura \texttt{Wrapper\_maximum} es similar a la anterior, consta de un puntero a \texttt{ConcurrentHashMap mapa}, uno a mutex \texttt{mutexLista}, y dos a iteradores de lista de string, \texttt{it} y \texttt{ends}. Básicamente, los que en la anterior eran iteradores, acá son punteros a los mismos. Esto lo hicimos de esta manera porque cada $thread$ va a armar un \texttt{mapa} distinto, así que cada uno trabaja con un \texttt{wrap} diferente, por lo que necesitamos pasarle punteros a los iteradores para que todos compartan los mismos (y así nos aseguramos de que carguen archivos distintos).

A su vez, la función auxiliar \texttt{thread\_maximum} es casi idéntica a \texttt{thread\_count\_words2}. La única diferencia es que al tratar con \texttt{it} y \texttt{ends}, hay que desreferenciarlos.

El pseudocódigo de \texttt{maximum(unsigned int p\_archivos, unsigned int p\_maximos, list<string>archs)} es el siguiente:

\begin{algorithm}[H]
\SetKwProg{Fn}{Función}{}{fin}

\SetAlgoLined
\Fn{maximum(p\_archivos, p\_maximos, archs)}{
	\texttt{wrap} $\leftarrow$ arreglo de \texttt{p\_archivos} \texttt{Wrapper\_maximums} \\
	\texttt{mutexLista} $\leftarrow$ nuevo mutex \\
	\texttt{it} $\leftarrow$ \texttt{archs.begin} \\
	\texttt{ends} $\leftarrow$ \texttt{archs.end} \\
	\ForEach{entrada de \texttt{wrap}}{
		asignarle direcciones de un nuevo \texttt{CHM}, \texttt{mutexList}, \texttt{it} y \texttt{ends} \\
	}
	crear \texttt{p\_archivos} threads con un puntero a una entrada de \texttt{wrap} y a \texttt{thread\_maximum} \\
	esperar que terminen los \texttt{p\_archivos} threads \\
	\texttt{mapa} $\leftarrow$ nuevo \texttt{CHM} \\
	\texttt{mapa} $\leftarrow$ merge de los mapas en las entradas de \texttt{wrap} \\
	devolver \texttt{mapa.\texttt{maximum}(p\_maximos)} \\
}
\caption{maximum}
\end{algorithm}

Como cada uno de los \texttt{p\_archivos} $threads$ arma su propio mapa, es necesario fusionar todos en uno solo para buscarle el máximo. Esto se hace recorriendo todas los pares de todas las entradas de cada \texttt{tabla}. Por cada par \texttt{(key, k)} recorrido se aplica \texttt{k} veces \texttt{addAndInc(key)} a \texttt{mapa}.

\subsection{Ejercicio 6}

Para este ejercicio había que repetir la funcionalidad del anterior usando la versión concurrente de \texttt{count\_words}, por lo que su código es muy simple.

\begin{algorithm}[H]
\SetKwProg{Fn}{Función}{}{fin}

\SetAlgoLined
\Fn{maximum2(p\_archivos, p\_maximos, archs)}{
	\texttt{mapa} $\leftarrow$ \texttt{count\_words(p\_archivos, archs)} \\
	devolver \texttt{mapa.maximum(p\_maximos)} \\
}
\caption{maximum2}
\end{algorithm}

En este ejercicio se pide además hacer una comparación con la implementación del ejercicio 5. La experimentación de esto se presenta en la siguiente sección.

\section{Experimentación}

Para comparar el rendimiento de la implementación del ejercicio 5 y el ejercicio 6 decidimos medir el tiempo en nanosegundos que toma ejecutar las funciones, para distintas cantidades de \textit{threads}. Sin embargo, ya que en ambas implementaciones tomar el máximo sobre el \texttt{CHM} \texttt{mapa} es exactamente igual (\texttt{mapa.maximum(p\_maximos)}), solo medimos el tiempo hasta que se termina de armar \texttt{mapa}. Viendo el pseudocódigo de cada ejercicio, lo que tomamos es el tiempo de ejecutar todas las líneas menos la última. Nos referiremos a este tiempo como \textit{ej5} y \textit{ej6} respectivamente.

Las mediciones fueron realizadas en una computadora con las siguientes especificaciones:
\begin{itemize}
\itemsep0em
\item Procesador: Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz x 4
\item Memoria: 8 GB DDR3
\item S.O.: Ubuntu 17.10 64 bits
\end{itemize}

Como primer experimento lo que hicimos fue armar 100 copias de un mismo archivo de 500 palabras, el cual generamos tomándolas aleatoriamente de un archivo de 10000 palabras en inglés. El archivo se genera sin palabras repetidas, pero al tener 100 copias del mismo en total cada palabra se repite 100 veces. A partir de esto ejecutamos \texttt{maximum} y \texttt{maximum2} con esta lista de 100 archivos iguales, pasando como parámetro \texttt{p\_archivos} de 1 a 100 para ver cómo influye la cantidad de \textit{threads}, y en cambio \texttt{p\_maximos} lo pusimos en una cantidad cualquiera ya que no influye en la medición que realizamos. Este proceso lo realizamos con 300 repeticiones.

Lo que esperamos es que \textit{ej5} en general sea mayor que \textit{ej6}, ya que el tener que hacer un merge de todos los \texttt{CHM} supone un cuello de botella que se realiza sin paralelismo. Además, creemos que incrementar \texttt{p\_archivos} solo dará mejoras sustanciales en los primeros valores y hay un punto en el que agregar muchos \textit{threads} no sirve tanto.

\begin{center}
   \includegraphics[height=5.85cm]{img/exp1.png}
   \captionof{figure}{Tiempo de ejecución promedio de \textit{ej5} y \textit{ej6} según \texttt{p\_archivos} con 100 archivos iguales}
   \label{fig:exp1}
\end{center}

Los resultados los presentamos graficados en la \textbf{Figura \ref{fig:exp1}}, y lo que podemos ver es que como esperábamos \textit{ej5} es mucho mayor que \textit{ej6}. También vemos que, salvo en los primeros valores, en \textit{ej5} hay un crecimiento del tiempo conforme \texttt{p\_archivos} aumenta. 

En \textit{ej6} esto no pasa, y además observamos que, tal cual habíamos predicho, el tiempo se reduce de forma importante en los primeros valores de \texttt{p\_archivos} (reduciendo a aproximadamente la mitad el tiempo donde solo hay 1 \textit{thread}), pero después este efecto desaparece, seguir agregando \textit{threads} no sirve para bajar el tiempo. Por esto creemos que en una implementación con paralelismo es necesario llevar a cabo una experimentación para determinar una cantidad de \textit{threads} óptima. 

Otra observación que podemos realizar es que en \textit{ej6} hay un pico en \texttt{p\_archivos = 62}. No fuimos capaces de determinar la causa de esta anomalía, creímos que podría tratarse de algo específico de la computadora en donde realizamos las mediciones, pero probando en otras obteníamos el mismo resultado patológico.

Para estudiar más en detalle, decidimos separar la medición de \textit{ej5} en dos. Por un lado tomamos el tiempo que se tarda en armar los \texttt{p\_archivos} \texttt{CHM} indivuales y por otro lado medimos el tiempo de realizar el merge de todos ellos en \texttt{mapa}. Llamaremos a estos tiempos \textit{ej5-load} y \textit{ej5-merge} respectivamente.

\begin{center}
   \includegraphics[height=5.85cm]{img/exp1-lm.png}
   \captionof{figure}{Tiempo de ejecución promedio de \textit{ej5-load}, \textit{ej5-merge} y \textit{ej6} según \texttt{p\_archivos} con 100 archivos iguales}
   \label{fig:exp1-lm}
\end{center}

Observando los resultados en la \textbf{Figura \ref{fig:exp1-lm}}, podemos ver cómo el merge hace que el ejercicio 5 tome mucho más tiempo, lo cual era esperable. Pero también vemos otro resultado interesante: Comparando \textit{ej5-load} contra \textit{ej6} podemos decir que para los primeros valores de \texttt{p\_archivos} el primero está por debajo del otro. Esto tiene sentido porque, aunque ambas funciones realizan operaciones muy similares en esta etapa, una diferencia importante entre ellas es que en el ejercicio 5 cada \textit{thread} se ocupa de un \texttt{CHM} propio, y entonces no se encuentra con bloqueos cuando se realizan los \texttt{addAndInc}, mientras que en el ejercicio 6 esto sí ocurre ya que todos los \textit{threads} modifican un mismo \texttt{CHM}.

Al aumentar \texttt{p\_archivos} la situación cambia, \textit{ej5-load} aumenta mucho llegando a superar a \textit{ej6}. Una posible explicación que encontramos es que esto se debe en la cantidad de \texttt{push\_front} realizados. En el ejercicio 5 esa función se aplica más veces porque cada \textit{thread} debe hacerlo para agregar una palabra a su \texttt{CMH}, independientemente si otro \textit{thread} ya lo había hecho en su propio \texttt{CHM}. En cambio en el ejercicio 6 cada palabra distinta se inserta solo una vez.

Nuestra hipótesis entonces es que si en vez de usar 100 archivos iguales usáramos archivos distintos \textit{ej5-load} sí se mantendría por debajo de \textit{ej6}. Para poner a prueba esto realizamos un nuevo experimento, de forma que los archivos sean distintos (aunque puede haber palabras repetidas entre ellos, cada uno se genera independientemente), de nuevo con 500 palabras cada uno. Además creemos que tener archivos distintos es un escenario más realista. Tomamos 60 repeticiones de las mediciones.

\begin{center}
   \includegraphics[height=5.85cm]{img/exp2.png}
   \includegraphics[height=5.85cm]{img/exp2-lm.png}
   \captionof{figure}{Tiempo de ejecución promedio de \textit{ej5}, \textit{ej5-load}, \textit{ej5-merge} y \textit{ej6} según \texttt{p\_archivos} con 100 archivos distintos}
   \label{fig:exp2}
\end{center}

La \textbf{Figura \ref{fig:exp2}} tiene graficados los tiempos medidos, a la izquierda con \textit{ej5} y a la derecha separándolo en \textit{ej5-load} y \textit{ej5-merge}. Comparando los resultados del experimento con 100 archivos iguales contra el de ahora vemos una diferencia muy distinguida entre los tiempos. En el primer caso los tiempos están en órdenes de 1e7, mientras que ahora son del orden de 1e8. Lo que ocurre es que cuando hay 100 archivos iguales solo hay en total 500 palabras distintas entre todos, pero cuando los archivos son distintos pueden haber muchas más claves diferentes. Esto hace que ahora los \texttt{CHM} generados tengan un tamaño considerablemente mayor, lo cual hace que operaciones como \texttt{addAndInc} y el proceso de merge tomen bastante más tiempo.


Ahora, analizando las diferencias entre las dos implementaciones, vemos que ocurre lo que esperábamos, \textit{ej5-load} es siempre menor a \textit{ej6}. En este caso los bloqueos no son el único factor, también hay que tener en cuenta que ahora los \texttt{CHM} individuales son más chicos que el \texttt{CHM} global, tienen menos claves porque solo contienen las de los archivos que revisan, mientras que todos los archivos en su totalidad tienen más palabras distintas, por lo que el \texttt{CHM} global que se crea en el ejercicio 6 es más grande y sus entradas toman más tiempo en recorrer cuando se hace \texttt{addAndInc}.

Sin embargo, a pesar de que cargar los archivos en distintos \texttt{CHM} es más rápido que hacerlo en uno solo (incluso vemos una mejora de la mitad de tiempo), vemos nuevamente que hacer un merge de todos toma una cantidad muy grande de tiempo, haciendo que lo que se había ganado en la paralelización del trabajo se pierda por completo. Es por esto que nuestra conclusión es que la mejor experimentación es la del ejercicio 6.


\newpage
\includepdf[scale=0.75,pages=1,pagecommand=\section{Apéndices}
\subsection{Apéndice A - Enunciado}]{./../../tp2-enunciado.pdf}
\includepdf[scale=0.75,pages=2-,pagecommand=]{./../../tp2-enunciado.pdf}

\subsection{Apéndice B - Aclaraciones}

A la clase \texttt{ConcurrentHashMap} le agregamos un constructor por copia y un operador de asignación, lo cual no era requerido por el enunciado pero lo necesitamos para lograr compilar los tests. A causa de esto, tuvimos que implementar también un constructor por copia para la clase \texttt{Lista}.

Las funciones requeridas en los ejercicio 2 a 6 las definimos dentro de la clase \texttt{ConcurrentHashMap} como \texttt{static}, nuevamente para lograr compilar los tests. En este caso, el enunciado pide explícitamente que no lo hagamos de esta forma, pero los tests así lo asumían.

\end{document}

